{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install etherscan-python\n",
    "!pip3 install mysql-connector\n",
    "!pip install coinmetrics-api-client\n",
    "!pip3 install ethereum-etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f348a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib_resources as resources\n",
    "import pandas as pd\n",
    "import sys\n",
    "import threading\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from etherscan import Etherscan\n",
    "from coinmetrics.api_client import CoinMetricsClient\n",
    "import etherscan\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0aed6bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1051 (42S02): Unknown table 'cryptologic_BE_Dev.alerts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4714/3526087086.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                  database='cryptologic_BE_Dev')\n\u001b[1;32m      4\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DROP TABLE alerts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/mysql/connector/cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W0212\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mServerCmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36m_handle_result\u001b[0;34m(self, packet)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpacket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# We have a text result set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 1051 (42S02): Unknown table 'cryptologic_BE_Dev.alerts'"
     ]
    }
   ],
   "source": [
    "conn = mysql.connector.MySQLConnection(user='admin', password='wWusLXWEsxNqaviwGPsP',\n",
    "                                 host='cryptologic-test-mysql-db.cyage1xxew24.us-east-1.rds.amazonaws.com',\n",
    "                                 database='cryptologic_BE_Dev')\n",
    "c = conn.cursor()\n",
    "c.execute('DROP TABLE alerts')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7653c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETHERSCAN_KEY = os.environ.get('ZAZGB7REEJ4TSG38SS9PT6MR55KN83ZZ43')\n",
    "eth = Etherscan('ZAZGB7REEJ4TSG38SS9PT6MR55KN83ZZ43')\n",
    "div=(10**18)\n",
    "client = CoinMetricsClient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187979f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Trx_From_Wallet', 'Trx_To_Wallet', 'Trx_Amount', 'Trx_Datetime', 'Trx_Hash', 'Trx_Gas', 'Trx_GasPrice', 'Trx_Status', 'Trx_Method_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2f6045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8032799.02492169\n"
     ]
    }
   ],
   "source": [
    "Token='0xCF3C8Be2e2C42331Da80EF210e9B1b307C03d36A'\n",
    "Wallet='0x3ab28ecedea6cdb6feed398e93ae8c7b316b1182'\n",
    "balance=(int(eth.get_acc_balance_by_token_and_contract_address(address=Wallet, contract_address=Token)))/div\n",
    "print(balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3db340",
   "metadata": {},
   "source": [
    "Fetch all transactions from a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c85f8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State starting from scratch\n",
      "Scanning events from blocks 11596497 - 15410584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current block: 11597951 (06-01-2021), blocks in a scan batch: 320, events processed in a batch 0:   0%|          | 1740/3814087 [00:37<22:34:46, 46.90it/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://summer-necessary-wish.discover.quiknode.pro/0f8072ec3941a0b0996c64aeb42bf46125b91126",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4714/2877863920.py\u001b[0m in \u001b[0;36m<cell line: 398>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4714/2877863920.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;31m# Run the scan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_chunks_scanned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscanner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_update_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4714/2877863920.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(self, start_block, end_block, start_chunk_size, progress_callback)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mactual_end_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_block_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_end_block\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;31m# Where does our current chunk scan ends - are we out of chain yet?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4714/2877863920.py\u001b[0m in \u001b[0;36mscan_chunk\u001b[0;34m(self, start_block, end_block)\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# Get UTC time when this event happened (block mined timestamp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;31m# from our in-memory cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mblock_when\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_when\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing event {evt['event']}, block: {evt['blockNumber']} count: {evt['blockNumber']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4714/2877863920.py\u001b[0m in \u001b[0;36mget_block_when\u001b[0;34m(block_num)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_block_when\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock_num\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblock_timestamps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mblock_timestamps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mblock_timestamps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4714/2877863920.py\u001b[0m in \u001b[0;36mget_block_timestamp\u001b[0;34m(self, block_num)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"\"\"Get Ethereum block timestamp\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mblock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBlockNotFound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# Block was not mined yet,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/eth.py\u001b[0m in \u001b[0;36mget_block\u001b[0;34m(self, block_identifier, full_transactions)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_identifier\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBlockIdentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_transactions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     ) -> BlockData:\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_identifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_transactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     get_code: Method[Callable[..., HexBytes]] = Method(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/module.py\u001b[0m in \u001b[0;36mcaller\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLogFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meth_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mresult_formatters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_formatters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnull_result_formatters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_formatters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         result = w3.manager.request_blocking(method_str,\n\u001b[0m\u001b[1;32m     58\u001b[0m                                              \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                                              \u001b[0merror_formatters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/manager.py\u001b[0m in \u001b[0;36mrequest_blocking\u001b[0;34m(self, method, params, error_formatters, null_result_formatters)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mMake\u001b[0m \u001b[0ma\u001b[0m \u001b[0msynchronous\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         return self.formatted_response(response,\n\u001b[1;32m    199\u001b[0m                                        \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/manager.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, method, params)\u001b[0m\n\u001b[1;32m    148\u001b[0m             self.middleware_onion)\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Making request. Method: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrequest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     async def _coro_make_request(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/middleware/formatting.py\u001b[0m in \u001b[0;36mmiddleware\u001b[0;34m(method, params)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_formatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_response_formatters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/middleware/gas_price_strategy.py\u001b[0m in \u001b[0;36mmiddleware\u001b[0;34m(method, params)\u001b[0m\n\u001b[1;32m     88\u001b[0m             )\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmiddleware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/middleware/formatting.py\u001b[0m in \u001b[0;36mmiddleware\u001b[0;34m(method, params)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_formatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_response_formatters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/middleware/attrdict.py\u001b[0m in \u001b[0;36mmiddleware\u001b[0;34m(method, params)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmiddleware\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRPCEndpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRPCResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'result'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/middleware/formatting.py\u001b[0m in \u001b[0;36mmiddleware\u001b[0;34m(method, params)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_formatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_response_formatters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/middleware/formatting.py\u001b[0m in \u001b[0;36mmiddleware\u001b[0;34m(method, params)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_formatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_response_formatters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/middleware/formatting.py\u001b[0m in \u001b[0;36mmiddleware\u001b[0;34m(method, params)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_formatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_response_formatters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/middleware/buffered_gas_estimate.py\u001b[0m in \u001b[0;36mmiddleware\u001b[0;34m(method, params)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 )\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmiddleware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/providers/rpc.py\u001b[0m in \u001b[0;36mmake_request\u001b[0;34m(self, method, params)\u001b[0m\n\u001b[1;32m     86\u001b[0m                           self.endpoint_uri, method)\n\u001b[1;32m     87\u001b[0m         \u001b[0mrequest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_rpc_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         raw_response = make_post_request(\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mrequest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/web3/_utils/request.py\u001b[0m in \u001b[0;36mmake_post_request\u001b[0;34m(endpoint_uri, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# https://github.com/python/mypy/issues/2582\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://summer-necessary-wish.discover.quiknode.pro/0f8072ec3941a0b0996c64aeb42bf46125b91126"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Tuple, Optional, Callable, List, Iterable, Dict, Any\n",
    "\n",
    "from web3 import Web3\n",
    "from web3.contract import Contract\n",
    "from web3.datastructures import AttributeDict\n",
    "from web3.exceptions import BlockNotFound\n",
    "from eth_abi.codec import ABICodec\n",
    "\n",
    "from web3._utils.filters import construct_event_filter_params\n",
    "from web3._utils.events import get_event_data\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EventScannerState(ABC):\n",
    "    \"\"\"Application state that remembers what blocks we have scanned in the case of crash.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_last_scanned_block(self) -> int:\n",
    "        \"\"\"Number of the last block we have scanned on the previous cycle.\n",
    "\n",
    "        :return: 0 if no blocks scanned yet\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def start_chunk(self, block_number: int):\n",
    "        \"\"\"Scanner is about to ask data of multiple blocks over JSON-RPC.\n",
    "\n",
    "        Start a database session if needed.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def end_chunk(self, block_number: int):\n",
    "        \"\"\"Scanner finished a number of blocks.\n",
    "\n",
    "        Persistent any data in your state now.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def process_event(self, block_when: datetime.datetime, event: AttributeDict) -> object:\n",
    "        \"\"\"Process incoming events.\n",
    "\n",
    "        This function takes raw events from Web3, transforms them to your application internal\n",
    "        format, then saves them in a database or some other state.\n",
    "\n",
    "        :param block_when: When this block was mined\n",
    "\n",
    "        :param event: Symbolic dictionary of the event data\n",
    "\n",
    "        :return: Internal state structure that is the result of event tranformation.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def delete_data(self, since_block: int) -> int:\n",
    "        \"\"\"Delete any data since this block was scanned.\n",
    "\n",
    "        Purges any potential minor reorg data.\n",
    "        \"\"\"\n",
    "\n",
    "class EventScanner:\n",
    "    \"\"\"Scan blockchain for events and try not to abuse JSON-RPC API too much.\n",
    "\n",
    "    Can be used for real-time scans, as it detects minor chain reorganisation and rescans.\n",
    "    Unlike the easy web3.contract.Contract, this scanner can scan events from multiple contracts at once.\n",
    "    For example, you can get all transfers from all tokens in the same scan.\n",
    "\n",
    "    You *should* disable the default `http_retry_request_middleware` on your provider for Web3,\n",
    "    because it cannot correctly throttle and decrease the `eth_getLogs` block number range.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w3: Web3, contract: Contract, state: EventScannerState, events: List, filters: Dict[str, Any],\n",
    "                 max_chunk_scan_size: int = 10000, max_request_retries: int = 30, request_retry_seconds: float = 3.0):\n",
    "        \"\"\"\n",
    "        :param contract: Contract\n",
    "        :param events: List of web3 Event we scan\n",
    "        :param filters: Filters passed to getLogs\n",
    "        :param max_chunk_scan_size: JSON-RPC API limit in the number of blocks we query. (Recommendation: 10,000 for mainnet, 500,000 for testnets)\n",
    "        :param max_request_retries: How many times we try to reattempt a failed JSON-RPC call\n",
    "        :param request_retry_seconds: Delay between failed requests to let JSON-RPC server to recover\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger = logger\n",
    "        self.contract = contract\n",
    "        self.w3 = w3\n",
    "        self.state = state\n",
    "        self.events = events\n",
    "        self.filters = filters\n",
    "\n",
    "        # Our JSON-RPC throttling parameters\n",
    "        self.min_scan_chunk_size = 10  # 12 s/block = 120 seconds period\n",
    "        self.max_scan_chunk_size = max_chunk_scan_size\n",
    "        self.max_request_retries = max_request_retries\n",
    "        self.request_retry_seconds = request_retry_seconds\n",
    "\n",
    "        # Factor how fast we increase the chunk size if results are found\n",
    "        # # (slow down scan after starting to get hits)\n",
    "        self.chunk_size_decrease = 0.5\n",
    "\n",
    "        # Factor how was we increase chunk size if no results found\n",
    "        self.chunk_size_increase = 2.0\n",
    "\n",
    "    @property\n",
    "    def address(self):\n",
    "        return self.token_address\n",
    "\n",
    "    def get_block_timestamp(self, block_num) -> datetime.datetime:\n",
    "        \"\"\"Get Ethereum block timestamp\"\"\"\n",
    "        try:\n",
    "            block_info = self.w3.eth.getBlock(block_num)\n",
    "        except BlockNotFound:\n",
    "            # Block was not mined yet,\n",
    "            # minor chain reorganisation?\n",
    "            return None\n",
    "        last_time = block_info[\"timestamp\"]\n",
    "        return datetime.datetime.utcfromtimestamp(last_time)\n",
    "\n",
    "    def get_suggested_scan_start_block(self):\n",
    "        \"\"\"Get where we should start to scan for new token events.\n",
    "\n",
    "        If there are no prior scans, start from block 1.\n",
    "        Otherwise, start from the last end block minus ten blocks.\n",
    "        We rescan the last ten scanned blocks in the case there were forks to avoid\n",
    "        misaccounting due to minor single block works (happens once in a hour in Ethereum).\n",
    "        These heurestics could be made more robust, but this is for the sake of simple reference implementation.\n",
    "        \"\"\"\n",
    "\n",
    "        end_block = self.get_last_scanned_block()\n",
    "        if end_block:\n",
    "            return max(1, end_block - self.NUM_BLOCKS_RESCAN_FOR_FORKS)\n",
    "        return 1\n",
    "\n",
    "    def get_suggested_scan_end_block(self):\n",
    "        \"\"\"Get the last mined block on Ethereum chain we are following.\"\"\"\n",
    "\n",
    "        # Do not scan all the way to the final block, as this\n",
    "        # block might not be mined yet\n",
    "        return self.w3.eth.blockNumber - 1\n",
    "\n",
    "    def get_last_scanned_block(self) -> int:\n",
    "        return self.state.get_last_scanned_block()\n",
    "\n",
    "    def delete_potentially_forked_block_data(self, after_block: int):\n",
    "        \"\"\"Purge old data in the case of blockchain reorganisation.\"\"\"\n",
    "        self.state.delete_data(after_block)\n",
    "\n",
    "    def scan_chunk(self, start_block, end_block) -> Tuple[int, datetime.datetime, list]:\n",
    "        \"\"\"Read and process events between to block numbers.\n",
    "\n",
    "        Dynamically decrease the size of the chunk if the case JSON-RPC server pukes out.\n",
    "\n",
    "        :return: tuple(actual end block number, when this block was mined, processed events)\n",
    "        \"\"\"\n",
    "\n",
    "        block_timestamps = {}\n",
    "        get_block_timestamp = self.get_block_timestamp\n",
    "\n",
    "        # Cache block timestamps to reduce some RPC overhead\n",
    "        # Real solution might include smarter models around block\n",
    "        def get_block_when(block_num):\n",
    "            if block_num not in block_timestamps:\n",
    "                block_timestamps[block_num] = get_block_timestamp(block_num)\n",
    "            return block_timestamps[block_num]\n",
    "\n",
    "        all_processed = []\n",
    "\n",
    "        for event_type in self.events:\n",
    "\n",
    "            # Callable that takes care of the underlying web3 call\n",
    "            def _fetch_events(_start_block, _end_block):\n",
    "                return _fetch_events_for_all_contracts(self.w3,\n",
    "                                                       event_type,\n",
    "                                                       self.filters,\n",
    "                                                       from_block=_start_block,\n",
    "                                                       to_block=_end_block)\n",
    "\n",
    "            # Do `n` retries on `eth_getLogs`,\n",
    "            # throttle down block range if needed\n",
    "            end_block, events = _retry_web3_call(\n",
    "                _fetch_events,\n",
    "                start_block=start_block,\n",
    "                end_block=end_block,\n",
    "                retries=self.max_request_retries,\n",
    "                delay=self.request_retry_seconds)\n",
    "\n",
    "            for evt in events:\n",
    "                idx = evt[\"logIndex\"]  # Integer of the log index position in the block, null when its pending\n",
    "\n",
    "                # We cannot avoid minor chain reorganisations, but\n",
    "                # at least we must avoid blocks that are not mined yet\n",
    "                assert idx is not None, \"Somehow tried to scan a pending block\"\n",
    "\n",
    "                block_number = evt[\"blockNumber\"]\n",
    "\n",
    "                # Get UTC time when this event happened (block mined timestamp)\n",
    "                # from our in-memory cache\n",
    "                block_when = get_block_when(block_number)\n",
    "\n",
    "                logger.debug(f\"Processing event {evt['event']}, block: {evt['blockNumber']} count: {evt['blockNumber']}\")\n",
    "                processed = self.state.process_event(block_when, evt)\n",
    "                all_processed.append(processed)\n",
    "\n",
    "        end_block_timestamp = get_block_when(end_block)\n",
    "        return end_block, end_block_timestamp, all_processed\n",
    "\n",
    "    def estimate_next_chunk_size(self, current_chuck_size: int, event_found_count: int):\n",
    "        \"\"\"Try to figure out optimal chunk size\n",
    "\n",
    "        Our scanner might need to scan the whole blockchain for all events\n",
    "\n",
    "        * We want to minimize API calls over empty blocks\n",
    "\n",
    "        * We want to make sure that one scan chunk does not try to process too many entries once, as we try to control commit buffer size and potentially asynchronous busy loop\n",
    "\n",
    "        * Do not overload node serving JSON-RPC API by asking data for too many events at a time\n",
    "\n",
    "        Currently Ethereum JSON-API does not have an API to tell when a first event occurred in a blockchain\n",
    "        and our heuristics try to accelerate block fetching (chunk size) until we see the first event.\n",
    "\n",
    "        These heurestics exponentially increase the scan chunk size depending on if we are seeing events or not.\n",
    "        When any transfers are encountered, we are back to scanning only a few blocks at a time.\n",
    "        It does not make sense to do a full chain scan starting from block 1, doing one JSON-RPC call per 20 blocks.\n",
    "        \"\"\"\n",
    "\n",
    "        if event_found_count > 0:\n",
    "            # When we encounter first events, reset the chunk size window\n",
    "            current_chuck_size = self.min_scan_chunk_size\n",
    "        else:\n",
    "            current_chuck_size *= self.chunk_size_increase\n",
    "\n",
    "        current_chuck_size = max(self.min_scan_chunk_size, current_chuck_size)\n",
    "        current_chuck_size = min(self.max_scan_chunk_size, current_chuck_size)\n",
    "        return int(current_chuck_size)\n",
    "\n",
    "    def scan(self, start_block, end_block, start_chunk_size=20, progress_callback=Optional[Callable]) -> Tuple[\n",
    "        list, int]:\n",
    "        \"\"\"Perform a token balances scan.\n",
    "\n",
    "        Assumes all balances in the database are valid before start_block (no forks sneaked in).\n",
    "\n",
    "        :param start_block: The first block included in the scan\n",
    "\n",
    "        :param end_block: The last block included in the scan\n",
    "\n",
    "        :param start_chunk_size: How many blocks we try to fetch over JSON-RPC on the first attempt\n",
    "\n",
    "        :param progress_callback: If this is an UI application, update the progress of the scan\n",
    "\n",
    "        :return: [All processed events, number of chunks used]\n",
    "        \"\"\"\n",
    "\n",
    "        assert start_block <= end_block\n",
    "\n",
    "        current_block = start_block\n",
    "\n",
    "        # Scan in chunks, commit between\n",
    "        chunk_size = start_chunk_size\n",
    "        last_scan_duration = last_logs_found = 0\n",
    "        total_chunks_scanned = 0\n",
    "\n",
    "        # All processed entries we got on this scan cycle\n",
    "        all_processed = []\n",
    "\n",
    "        while current_block <= end_block:\n",
    "\n",
    "            self.state.start_chunk(current_block, chunk_size)\n",
    "\n",
    "            # Print some diagnostics to logs to try to fiddle with real world JSON-RPC API performance\n",
    "            estimated_end_block = current_block + chunk_size\n",
    "            logger.debug(\n",
    "                f\"Scanning token transfers for blocks: {current_block} - {estimated_end_block}, chunk size {chunk_size}, last chunk scan took {last_scan_duration}, last logs found {last_logs_found}\"\n",
    "            )\n",
    "\n",
    "            start = time.time()\n",
    "            actual_end_block, end_block_timestamp, new_entries = self.scan_chunk(current_block, estimated_end_block)\n",
    "\n",
    "            # Where does our current chunk scan ends - are we out of chain yet?\n",
    "            current_end = actual_end_block\n",
    "\n",
    "            last_scan_duration = time.time() - start\n",
    "            all_processed += new_entries\n",
    "\n",
    "            # Print progress bar\n",
    "            if progress_callback:\n",
    "                progress_callback(start_block, end_block, current_block, end_block_timestamp, chunk_size, len(new_entries))\n",
    "\n",
    "            # Try to guess how many blocks to fetch over `eth_getLogs` API next time\n",
    "            chunk_size = self.estimate_next_chunk_size(chunk_size, len(new_entries))\n",
    "\n",
    "            # Set where the next chunk starts\n",
    "            current_block = current_end + 1\n",
    "            total_chunks_scanned += 1\n",
    "            self.state.end_chunk(current_end)\n",
    "            time.sleep(1)\n",
    "\n",
    "        return all_processed, total_chunks_scanned\n",
    "    \n",
    "def _retry_web3_call(func, start_block, end_block, retries, delay) -> Tuple[int, list]:\n",
    "    \"\"\"A custom retry loop to throttle down block range.\n",
    "\n",
    "    If our JSON-RPC server cannot serve all incoming `eth_getLogs` in a single request,\n",
    "    we retry and throttle down block range for every retry.\n",
    "\n",
    "    For example, Go Ethereum does not indicate what is an acceptable response size.\n",
    "    It just fails on the server-side with a \"context was cancelled\" warning.\n",
    "\n",
    "    :param func: A callable that triggers Ethereum JSON-RPC, as func(start_block, end_block)\n",
    "    :param start_block: The initial start block of the block range\n",
    "    :param end_block: The initial start block of the block range\n",
    "    :param retries: How many times we retry\n",
    "    :param delay: Time to sleep between retries\n",
    "    \"\"\"\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            return end_block, func(start_block, end_block)\n",
    "        except Exception as e:\n",
    "            # Assume this is HTTPConnectionPool(host='localhost', port=8545): Read timed out. (read timeout=10)\n",
    "            # from Go Ethereum. This translates to the error \"context was cancelled\" on the server side:\n",
    "            # https://github.com/ethereum/go-ethereum/issues/20426\n",
    "            if i < retries - 1:\n",
    "                # Give some more verbose info than the default middleware\n",
    "                logger.warning(\n",
    "                    f\"Retrying events for block range {start_block} - {end_block} ({end_block-start_block}) failed with {e} , retrying in {delay} seconds\")\n",
    "                # Decrease the `eth_getBlocks` range\n",
    "                end_block = start_block + ((end_block - start_block) // 2)\n",
    "                # Let the JSON-RPC to recover e.g. from restart\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                logger.warning(\"Out of retries\")\n",
    "                raise\n",
    "\n",
    "    \n",
    "def _fetch_events_for_all_contracts(\n",
    "        w3,\n",
    "        event,\n",
    "        argument_filters: Dict[str, Any],\n",
    "        from_block: int,\n",
    "        to_block: int) -> Iterable:\n",
    "    \"\"\"Get events using eth_getLogs API.\n",
    "\n",
    "    This method is detached from any contract instance.\n",
    "\n",
    "    This is a stateless method, as opposed to createFilter.\n",
    "    It can be safely called against nodes which do not provide `eth_newFilter` API, like Infura.\n",
    "    \"\"\"\n",
    "\n",
    "    if from_block is None:\n",
    "        raise TypeError(\"Missing mandatory keyword argument to getLogs: fromBlock\")\n",
    "\n",
    "    # Currently no way to poke this using a public Web3.py API.\n",
    "    # This will return raw underlying ABI JSON object for the event\n",
    "    abi = event._get_event_abi()\n",
    "\n",
    "    # Depending on the Solidity version used to compile\n",
    "    # the contract that uses the ABI,\n",
    "    # it might have Solidity ABI encoding v1 or v2.\n",
    "    # We just assume the default that you set on Web3 object here.\n",
    "    # More information here https://eth-abi.readthedocs.io/en/latest/index.html\n",
    "    codec: ABICodec = w3.codec\n",
    "\n",
    "    # Here we need to poke a bit into Web3 internals, as this\n",
    "    # functionality is not exposed by default.\n",
    "    # Construct JSON-RPC raw filter presentation based on human readable Python descriptions\n",
    "    # Namely, convert event names to their keccak signatures\n",
    "    # More information here:\n",
    "    # https://github.com/ethereum/web3.py/blob/e176ce0793dafdd0573acc8d4b76425b6eb604ca/web3/_utils/filters.py#L71\n",
    "    data_filter_set, event_filter_params = construct_event_filter_params(\n",
    "        abi,\n",
    "        codec,\n",
    "        address=argument_filters.get(\"address\"),\n",
    "        argument_filters=argument_filters,\n",
    "        fromBlock=from_block,\n",
    "        toBlock=to_block\n",
    "    )\n",
    "\n",
    "    logger.debug(f\"Querying eth_getLogs with the following parameters: {event_filter_params}\")\n",
    "\n",
    "    # Call JSON-RPC API on your Ethereum node.\n",
    "    # get_logs() returns raw AttributedDict entries\n",
    "    logs = w3.eth.get_logs(event_filter_params)\n",
    "\n",
    "    # Convert raw binary data to Python proxy objects as described by ABI\n",
    "    all_events = []\n",
    "    for log in logs:\n",
    "        # Convert raw JSON-RPC log result to human readable event by using ABI data\n",
    "        # More information how processLog works here\n",
    "        # https://github.com/ethereum/web3.py/blob/fbaf1ad11b0c7fac09ba34baff2c256cffe0a148/web3/_utils/events.py#L200\n",
    "        evt = get_event_data(codec, abi, log)\n",
    "        # Note: This was originally yield,\n",
    "        # but deferring the timeout exception caused the throttle logic not to work\n",
    "        all_events.append(evt)\n",
    "    return all_events\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Simple demo that scans all the token transfers of RCC token (11k).\n",
    "    # The demo supports persistant state by using a JSON file.\n",
    "    # You will need an Ethereum node for this.\n",
    "    # Running this script will consume around 20k JSON-RPC calls.\n",
    "    # With locally running Geth, the script takes 10 minutes.\n",
    "    # The resulting JSON state file is 2.9 MB.\n",
    "    import sys\n",
    "    import json\n",
    "    from web3.providers.rpc import HTTPProvider\n",
    "\n",
    "    # We use tqdm library to render a nice progress bar in the console\n",
    "    # https://pypi.org/project/tqdm/\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # RCC has around 11k Transfer events\n",
    "    # https://etherscan.io/token/0x9b6443b0fb9c241a7fdac375595cea13e6b7807a\n",
    "    RCC_ADDRESS = \"0xCF3C8Be2e2C42331Da80EF210e9B1b307C03d36A\"\n",
    "\n",
    "    # Reduced ERC-20 ABI, only Transfer event\n",
    "    ABI = \"\"\"[\n",
    "        {\n",
    "            \"anonymous\": false,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"indexed\": true,\n",
    "                    \"name\": \"from\",\n",
    "                    \"type\": \"address\"\n",
    "                },\n",
    "                {\n",
    "                    \"indexed\": true,\n",
    "                    \"name\": \"to\",\n",
    "                    \"type\": \"address\"\n",
    "                },\n",
    "                {\n",
    "                    \"indexed\": false,\n",
    "                    \"name\": \"value\",\n",
    "                    \"type\": \"uint256\"\n",
    "                }\n",
    "            ],\n",
    "            \"name\": \"Transfer\",\n",
    "            \"type\": \"event\"\n",
    "        }\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    class JSONifiedState(EventScannerState):\n",
    "        \"\"\"Store the state of scanned blocks and all events.\n",
    "\n",
    "        All state is an in-memory dict.\n",
    "        Simple load/store massive JSON on start up.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            self.state = None\n",
    "            self.fname = \"transfers.json\"\n",
    "            # How many second ago we saved the JSON file\n",
    "            self.last_save = 0\n",
    "\n",
    "        def reset(self):\n",
    "            \"\"\"Create initial state of nothing scanned.\"\"\"\n",
    "            self.state = {\n",
    "                \"last_scanned_block\": 0,\n",
    "                \"blocks\": {},\n",
    "            }\n",
    "\n",
    "        def restore(self):\n",
    "            \"\"\"Restore the last scan state from a file.\"\"\"\n",
    "            try:\n",
    "                self.state = json.load(open(self.fname, \"rt\"))\n",
    "                print(f\"Restored the state, previously {self.state['last_scanned_block']} blocks have been scanned\")\n",
    "            except (IOError, json.decoder.JSONDecodeError):\n",
    "                print(\"State starting from scratch\")\n",
    "                self.reset()\n",
    "\n",
    "        def save(self):\n",
    "            \"\"\"Save everything we have scanned so far in a file.\"\"\"\n",
    "            with open(self.fname, \"wt\") as f:\n",
    "                json.dump(self.state, f)\n",
    "            self.last_save = time.time()\n",
    "\n",
    "        #\n",
    "        # EventScannerState methods implemented below\n",
    "        #\n",
    "\n",
    "        def get_last_scanned_block(self):\n",
    "            \"\"\"The number of the last block we have stored.\"\"\"\n",
    "            return self.state[\"last_scanned_block\"]\n",
    "\n",
    "        def delete_data(self, since_block):\n",
    "            \"\"\"Remove potentially reorganised blocks from the scan data.\"\"\"\n",
    "            for block_num in range(since_block, self.get_last_scanned_block()):\n",
    "                if block_num in self.state[\"blocks\"]:\n",
    "                    del self.state[\"blocks\"][block_num]\n",
    "\n",
    "        def start_chunk(self, block_number, chunk_size):\n",
    "            pass\n",
    "\n",
    "        def end_chunk(self, block_number):\n",
    "            \"\"\"Save at the end of each block, so we can resume in the case of a crash or CTRL+C\"\"\"\n",
    "            # Next time the scanner is started we will resume from this block\n",
    "            self.state[\"last_scanned_block\"] = block_number\n",
    "\n",
    "            # Save the database file for every minute\n",
    "            if time.time() - self.last_save > 60:\n",
    "                self.save()\n",
    "\n",
    "        def process_event(self, block_when: datetime.datetime, event: AttributeDict) -> str:\n",
    "            \"\"\"Record a ERC-20 transfer in our database.\"\"\"\n",
    "            # Events are keyed by their transaction hash and log index\n",
    "            # One transaction may contain multiple events\n",
    "            # and each one of those gets their own log index\n",
    "\n",
    "            # event_name = event.event # \"Transfer\"\n",
    "            log_index = event.logIndex  # Log index within the block\n",
    "            # transaction_index = event.transactionIndex  # Transaction index within the block\n",
    "            txhash = event.transactionHash.hex()  # Transaction hash\n",
    "            block_number = event.blockNumber\n",
    "\n",
    "            # Convert ERC-20 Transfer event to our internal format\n",
    "            args = event[\"args\"]\n",
    "            transfer = {\n",
    "                \"from\": args[\"from\"],\n",
    "                \"to\": args.to,\n",
    "                \"value\": args.value,\n",
    "                \"timestamp\": block_when.isoformat(),\n",
    "            }\n",
    "\n",
    "            # Create empty dict as the block that contains all transactions by txhash\n",
    "            if block_number not in self.state[\"blocks\"]:\n",
    "                self.state[\"blocks\"][block_number] = {}\n",
    "\n",
    "            block = self.state[\"blocks\"][block_number]\n",
    "            if txhash not in block:\n",
    "                # We have not yet recorded any transfers in this transaction\n",
    "                # (One transaction may contain multiple events if executed by a smart contract).\n",
    "                # Create a tx entry that contains all events by a log index\n",
    "                self.state[\"blocks\"][block_number][txhash] = {}\n",
    "\n",
    "            # Record ERC-20 transfer in our database\n",
    "            self.state[\"blocks\"][block_number][txhash][log_index] = transfer\n",
    "\n",
    "            # Return a pointer that allows us to look up this event later if needed\n",
    "            return f\"{block_number}-{txhash}-{log_index}\"\n",
    "\n",
    "    def run():\n",
    "\n",
    "        if len(sys.argv) < 2:\n",
    "            print(\"Usage: eventscanner.py http://your-node-url\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        api_url = \"https://summer-necessary-wish.discover.quiknode.pro/0f8072ec3941a0b0996c64aeb42bf46125b91126\"\n",
    "\n",
    "        # Enable logs to the stdout.\n",
    "        # DEBUG is very verbose level\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "        provider = HTTPProvider(api_url)\n",
    "\n",
    "        # Remove the default JSON-RPC retry middleware\n",
    "        # as it correctly cannot handle eth_getLogs block range\n",
    "        # throttle down.\n",
    "        provider.middlewares.clear()\n",
    "\n",
    "        w3 = Web3(provider)\n",
    "\n",
    "        # Prepare stub ERC-20 contract object\n",
    "        abi = json.loads(ABI)\n",
    "        ERC20 = w3.eth.contract(abi=abi)\n",
    "\n",
    "        # Restore/create our persistent state\n",
    "        state = JSONifiedState()\n",
    "        state.restore()\n",
    "\n",
    "        # chain_id: int, w3: Web3, abi: Dict, state: EventScannerState, events: List, filters: Dict, max_chunk_scan_size: int=10000\n",
    "        scanner = EventScanner(\n",
    "            w3=w3,\n",
    "            contract=ERC20,\n",
    "            state=state,\n",
    "            events=[ERC20.events.Transfer],\n",
    "            filters={\"address\": RCC_ADDRESS},\n",
    "            # How many maximum blocks at the time we request from JSON-RPC\n",
    "            # and we are unlikely to exceed the response size limit of the JSON-RPC server\n",
    "            max_chunk_scan_size=10000\n",
    "        )\n",
    "\n",
    "        # Assume we might have scanned the blocks all the way to the last Ethereum block\n",
    "        # that mined a few seconds before the previous scan run ended.\n",
    "        # Because there might have been a minor Etherueum chain reorganisations\n",
    "        # since the last scan ended, we need to discard\n",
    "        # the last few blocks from the previous scan results.\n",
    "        chain_reorg_safety_blocks = 10\n",
    "        scanner.delete_potentially_forked_block_data(state.get_last_scanned_block() - chain_reorg_safety_blocks)\n",
    "\n",
    "        # Scan from [last block scanned] - [latest ethereum block]\n",
    "        # Note that our chain reorg safety blocks cannot go negative\n",
    "        start_block = 11596497 #max(state.get_last_scanned_block() - chain_reorg_safety_blocks, 0)\n",
    "        end_block = scanner.get_suggested_scan_end_block()\n",
    "        blocks_to_scan = end_block - start_block\n",
    "\n",
    "        print(f\"Scanning events from blocks {start_block} - {end_block}\")\n",
    "\n",
    "        # Render a progress bar in the console\n",
    "        start = time.time()\n",
    "        with tqdm(total=blocks_to_scan) as progress_bar:\n",
    "            def _update_progress(start, end, current, current_block_timestamp, chunk_size, events_count):\n",
    "                if current_block_timestamp:\n",
    "                    formatted_time = current_block_timestamp.strftime(\"%d-%m-%Y\")\n",
    "                else:\n",
    "                    formatted_time = \"no block time available\"\n",
    "                progress_bar.set_description(f\"Current block: {current} ({formatted_time}), blocks in a scan batch: {chunk_size}, events processed in a batch {events_count}\")\n",
    "                progress_bar.update(chunk_size)\n",
    "\n",
    "            # Run the scan\n",
    "            result, total_chunks_scanned = scanner.scan(start_block, end_block, progress_callback=_update_progress)\n",
    "\n",
    "        state.save()\n",
    "        duration = time.time() - start\n",
    "        print(f\"Scanned total {len(result)} Transfer events, in {duration} seconds, total {total_chunks_scanned} chunk scans performed\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "trx_contract_file=open('transfers.json','r')\n",
    "trx_by_contract=trx_contract_file.read()\n",
    "\n",
    "obj=json.loads(trx_by_contract)\n",
    "obj_list = list(obj['blocks'].items())\n",
    "\n",
    "curr=obj_list[2][1] #mudo o primeiro field\n",
    "key=list(obj_list[2][1]) #mudo o primeiro field\n",
    "\n",
    "curr_in=curr[key[0]]\n",
    "key_in=list(curr_in)\n",
    "\n",
    "fields=curr_in[key_in[0]]\n",
    "key[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d377278",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4714/3147923106.py\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_alert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def check_trx_value(max_trx_value, curr_value):\n",
    "    if curr_value > max_trx_value:\n",
    "        return 0\n",
    "\n",
    "def check_perc_var(df, max_perc_var, curr_from, curr_to, curr_value):\n",
    "\n",
    "    if curr_from in df.index and ((curr_value)/(df.at[curr_from, \"balance\"]*100+1))>max_perc_var:\n",
    "        return curr_from\n",
    "    if curr_to in df.index and ((curr_value)/(df.at[curr_to, \"balance\"]*100+1))>max_perc_var:\n",
    "        return curr_to\n",
    "    else:    \n",
    "        pass\n",
    "    \n",
    "def check_amount_mv_time(df, mv_time_frame, curr_from, curr_to):\n",
    "    \n",
    "    mv_from=df.at[curr_from, \"mv_time_frame\"]\n",
    "    mv_to= df.at[curr_to, \"mv_time_frame\"]\n",
    "    if mv_from>mv_time_frame:\n",
    "        return curr_from\n",
    "    if mv_to>mv_time_frame:\n",
    "        return curr_to\n",
    "    else:\n",
    "        pass\n",
    "       \n",
    "def check_amount_address(df, mv_time_frame, curr_from, curr_to, max_balance):\n",
    "    bal_from=df.at[curr_from, \"balance\"]\n",
    "    bal_to=df.at[curr_to, \"balance\"]\n",
    "    if bal_from>max_balance:\n",
    "        return curr_from\n",
    "    if bal_to>max_balance:\n",
    "        return curr_to\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def check_mv_time_frame(df, curr_add, curr_time, curr_time_last, mv_time_frame):\n",
    "    if pd.Timedelta(pd.to_datetime(curr_time)-pd.to_datetime(curr_time_last))<=time_frame:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def update_tokendb(df, df_alert, curr_value, curr_from, curr_to, curr_time, max_perc_var, key, mv_time_frame, max_balance):\n",
    "\n",
    "    check_perc = check_perc_var(df, max_perc_var, curr_from, curr_to, curr_value)\n",
    "    if check_perc is not None:\n",
    "        df_alert = df_alert.append({'type': \"max_perc_var\", 'trx_hash': key, 'wallet_involved':check, 'timestamp': curr_time}, ignore_index=True)\n",
    "\n",
    "#in case no add is at db \n",
    "\n",
    "    if curr_from in df.index and curr_to in df.index:\n",
    "        df.at[curr_from, \"balance\"]-=curr_value\n",
    "        df.at[curr_to, \"balance\"]+=curr_value\n",
    "        if check_mv_time_frame(df, curr_from, curr_time, df.at[curr_from, \"last_trx_time\"], time_frame):\n",
    "            df.at[curr_from, \"mv_time_frame\"]+=curr_value\n",
    "        else:\n",
    "            df.at[curr_from, \"last_trx_time\"]=curr_time\n",
    "            df.at[curr_from, \"mv_time_frame\"]=curr_value\n",
    "            if check_mv_time_frame(df, curr_to, curr_time, df.at[curr_to, \"last_trx_time\"], time_frame):\n",
    "                df.at[curr_to, \"mv_time_frame\"]+=curr_value\n",
    "            else:\n",
    "                df.at[curr_to, \"last_trx_time\"]=curr_time\n",
    "                df.at[curr_to, \"mv_time_frame\"]=curr_value\n",
    "                \n",
    "        check_time=check_amount_mv_time(df, mv_time_frame, curr_from, curr_to)\n",
    "        if check_time is not None:\n",
    "            df_alert = df_alert.append({'type': \"amount_mv_time\", 'trx_hash': key, 'wallet_involved':check_time, 'timestamp': curr_time}, ignore_index=True) \n",
    "\n",
    "        check_bal=check_amount_address(df, mv_time_frame, curr_from, curr_to, max_balance)\n",
    "        if check_time is not None:\n",
    "            df_alert = df_alert.append({'type': \"max_balance\", 'trx_hash': key, 'wallet_involved':check_bal, 'timestamp': curr_time}, ignore_index=True) \n",
    "\n",
    "        \n",
    "        \n",
    "#in case from address is but to address isn't in db\n",
    "                \n",
    "    if (curr_from in df.index) and (curr_to not in df.index):\n",
    "        df.at[curr_from, \"balance\"]-=curr_value\n",
    "        df = pd.concat([df, pd.DataFrame({'balance':curr_value, 'mv_time_frame':curr_value, 'last_trx_time': curr_time}, index=[curr_to])])\n",
    "        if check_mv_time_frame(df, curr_from, curr_time, df.at[curr_from, \"last_trx_time\"], time_frame):\n",
    "            df.at[curr_from, \"mv_time_frame\"]+=curr_value\n",
    "        else:\n",
    "            df.at[curr_from, \"last_trx_time\"]=curr_time\n",
    "            df.at[curr_from, \"mv_time_frame\"]=curr_value\n",
    "        \n",
    "        check_time=check_amount_mv_time(df, mv_time_frame, curr_from, curr_to)\n",
    "        if check_time is not None:\n",
    "            df_alert = df_alert.append({'type': \"amount_mv_time\", 'trx_hash': key, 'wallet_involved':check_time, 'timestamp': curr_time}, ignore_index=True) \n",
    "\n",
    "        check_bal=check_amount_address(df, mv_time_frame, curr_from, curr_to, max_balance)\n",
    "        if check_time is not None:\n",
    "            df_alert = df_alert.append({'type': \"max_balance\", 'trx_hash': key, 'wallet_involved':check_bal, 'timestamp': curr_time}, ignore_index=True) \n",
    "\n",
    "\n",
    "#in case to add is but from isn't in db\n",
    "            \n",
    "    if (curr_from not in df.index) and (curr_to in df.index):\n",
    "        df.at[curr_to, \"balance\"]+=curr_value\n",
    "        if check_mv_time_frame(df, curr_to, curr_time, df.at[curr_to, \"last_trx_time\"], time_frame):\n",
    "            df.at[curr_to, \"mv_time_frame\"]+=curr_value\n",
    "            \n",
    "        else:\n",
    "            df.at[curr_to, \"last_trx_time\"]=curr_time\n",
    "            df.at[curr_to, \"mv_time_frame\"]=curr_value\n",
    "    \n",
    "        mv_to=df.at[curr_to, \"mv_time_frame\"]\n",
    "        if mv_to>mv_time_frame:\n",
    "            df_alert = df_alert.append({'type': \"amount_mv_time\", 'trx_hash': key, 'wallet_involved':curr_to, 'timestamp': curr_time}, ignore_index=True)     \n",
    "        mv_to=df.at[curr_to, \"balance\"]\n",
    "        if mv_to>max_balance:\n",
    "            df_alert = df_alert.append({'type': \"max_balance\", 'trx_hash': key, 'wallet_involved':curr_to, 'timestamp': curr_time}, ignore_index=True)\n",
    "#in case no add is at db\n",
    "            \n",
    "    if (curr_from not in df.index) and (curr_to  not in df.index):\n",
    "        df = pd.concat([df, pd.DataFrame({'balance':curr_value, 'mv_time_frame':curr_value, 'last_trx_time': curr_time}, index=[curr_to])])  \n",
    "    \n",
    "    check_mv_time = check_amount_mv_time(df, mv_time_frame, curr_from, curr_to)\n",
    "    if check_mv_time is not None:\n",
    "        df_alert = df_alert.append({'type': \"move_timeframe\", 'trx_hash': key, 'wallet_involved':check_mv_time, 'timestamp': curr_time}, ignore_index=True)\n",
    "\n",
    "    return df, df_alert\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "85be6d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>trx_hash</th>\n",
       "      <th>wallet_involved</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0x8e8ec56090d0dd0bc8c2ba0f23f88ad75ae8ba36c63b...</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-12-28T19:47:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0x7701d2bceb7ec5ba62d1abc2eebb0770da45685b2842...</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-12-29T04:34:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0x1afcea1121eb9b8fc315c151894a1aaa42a2589fceb2...</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-12-30T04:21:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0x31900c4f195198d0d3e834ba23c70e0c956362005794...</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-12-30T05:22:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0xf2b80c06f7c0b0b787f0e2336e2c54a46ed04f22339e...</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-12-30T12:19:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0x3cceb6ae327939e80ea378390d78200644f59a1d4574...</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-05T08:38:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0xf549ae9582133df2f9d3460237663372ef19550bd72c...</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-05T13:08:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0x541ab658064a8762371bb3b75869f456a82f04304576...</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-05T17:09:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0x33f38a9f3887b3256a5dfd0d3c6bc193d996dfffec7f...</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-05T18:49:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>max_perc_var</td>\n",
       "      <td>0xb0746f3533206fb12e8224846853c3e25de2b8355832...</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-05T19:14:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             type                                           trx_hash  \\\n",
       "0    max_perc_var  0x8e8ec56090d0dd0bc8c2ba0f23f88ad75ae8ba36c63b...   \n",
       "1    max_perc_var  0x7701d2bceb7ec5ba62d1abc2eebb0770da45685b2842...   \n",
       "2    max_perc_var  0x1afcea1121eb9b8fc315c151894a1aaa42a2589fceb2...   \n",
       "3    max_perc_var  0x31900c4f195198d0d3e834ba23c70e0c956362005794...   \n",
       "4    max_perc_var  0xf2b80c06f7c0b0b787f0e2336e2c54a46ed04f22339e...   \n",
       "..            ...                                                ...   \n",
       "253  max_perc_var  0x3cceb6ae327939e80ea378390d78200644f59a1d4574...   \n",
       "254  max_perc_var  0xf549ae9582133df2f9d3460237663372ef19550bd72c...   \n",
       "255  max_perc_var  0x541ab658064a8762371bb3b75869f456a82f04304576...   \n",
       "256  max_perc_var  0x33f38a9f3887b3256a5dfd0d3c6bc193d996dfffec7f...   \n",
       "257  max_perc_var  0xb0746f3533206fb12e8224846853c3e25de2b8355832...   \n",
       "\n",
       "    wallet_involved            timestamp  \n",
       "0              None  2020-12-28T19:47:29  \n",
       "1              None  2020-12-29T04:34:38  \n",
       "2              None  2020-12-30T04:21:33  \n",
       "3              None  2020-12-30T05:22:41  \n",
       "4              None  2020-12-30T12:19:22  \n",
       "..              ...                  ...  \n",
       "253            None  2021-01-05T08:38:26  \n",
       "254            None  2021-01-05T13:08:05  \n",
       "255            None  2021-01-05T17:09:08  \n",
       "256            None  2021-01-05T18:49:22  \n",
       "257            None  2021-01-05T19:14:50  \n",
       "\n",
       "[258 rows x 4 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_trx_value=800000000\n",
    "time_frame=pd.Timedelta(1, \"d\")\n",
    "mv_time_frame=100000000\n",
    "max_balance=100000000\n",
    "max_perc_var=100\n",
    "\n",
    "df = pd.DataFrame(columns = ['balance', 'mv_time_frame', 'last_trx_time'])\n",
    "df_alert = pd.DataFrame(columns = ['type', 'trx_hash', 'wallet_involved', 'timestamp'])\n",
    "for i in range(len(obj_list)):\n",
    "    curr=obj_list[i][1] \n",
    "    key=list(obj_list[i][1]) \n",
    "    \n",
    "    for j in range(len(curr)):\n",
    "        curr_in=curr[key[0]]\n",
    "        key_in=list(curr_in)\n",
    "        fields=curr_in[key_in[0]]\n",
    "        curr_value=int(fields['value'])/(10**18)\n",
    "        curr_from=fields['from']\n",
    "        curr_to=fields['to']\n",
    "        curr_time=fields['timestamp']\n",
    "        check = check_trx_value(max_trx_value, curr_value)\n",
    "        if check is not None:\n",
    "            df_alert = df_alert.append({'type': \"max_trx_value\", 'trx_hash': key[0], 'wallet_involved':check, 'timestamp': curr_time}, ignore_index=True)\n",
    "            \n",
    "        df, df_alert=update_tokendb(df, df_alert, curr_value, curr_from, curr_to, curr_time, max_perc_var, key[0], mv_time_frame, max_balance)\n",
    "        \n",
    "#The table created here might possess negative values due to minting\n",
    "df_alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "bf27145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#alter this block when you have time\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "url = 'mysql+mysqlconnector://admin:wWusLXWEsxNqaviwGPsP@cryptologic-test-mysql-db.cyage1xxew24.us-east-1.rds.amazonaws.com:3306/cryptologic_BE_Dev'\n",
    "engine = sqlalchemy.create_engine(url)\n",
    "df_alert.to_sql(\"alerts\", engine, if_exists=\"append\", index= False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
